{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b25d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from anomaly_detector import AnomalyDetector\n",
    "from visualization import AadhaarVisualizer\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úì Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad4b88",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading processed datasets...\")\n",
    "\n",
    "enrolment_df = pd.read_parquet('../outputs/enrolment_processed.parquet')\n",
    "demographic_df = pd.read_parquet('../outputs/demographic_processed.parquet')\n",
    "biometric_df = pd.read_parquet('../outputs/biometric_processed.parquet')\n",
    "\n",
    "print(f\"‚úì Enrolment: {len(enrolment_df):,} records\")\n",
    "print(f\"‚úì Demographic: {len(demographic_df):,} records\")\n",
    "print(f\"‚úì Biometric: {len(biometric_df):,} records\")\n",
    "\n",
    "# Initialize detector\n",
    "detector = AnomalyDetector()\n",
    "visualizer = AadhaarVisualizer(output_dir='../outputs/figures')\n",
    "\n",
    "print(\"‚úì Anomaly detector initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c2db2",
   "metadata": {},
   "source": [
    "## 2. STATISTICAL OUTLIER DETECTION\n",
    "\n",
    "### 2.1 IQR Method - Enrolment Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare daily aggregation\n",
    "daily_enrol = enrolment_df.groupby('date')['total_enrolments'].sum().reset_index()\n",
    "\n",
    "# Detect outliers using IQR\n",
    "iqr_outliers = detector.detect_outliers_iqr(\n",
    "    daily_enrol['total_enrolments'].values,\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "print(f\"=== IQR OUTLIER DETECTION ===\\n\")\n",
    "print(f\"Total days: {len(daily_enrol)}\")\n",
    "print(f\"Outliers detected: {iqr_outliers['n_outliers']}\")\n",
    "print(f\"Outlier percentage: {iqr_outliers['outlier_percentage']:.2f}%\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Q1: {iqr_outliers['q1']:,.0f}\")\n",
    "print(f\"  Q3: {iqr_outliers['q3']:,.0f}\")\n",
    "print(f\"  IQR: {iqr_outliers['iqr']:,.0f}\")\n",
    "print(f\"  Lower bound: {iqr_outliers['lower_bound']:,.0f}\")\n",
    "print(f\"  Upper bound: {iqr_outliers['upper_bound']:,.0f}\")\n",
    "\n",
    "# Mark outliers in dataframe\n",
    "daily_enrol['is_outlier_iqr'] = iqr_outliers['is_outlier']\n",
    "outlier_days = daily_enrol[daily_enrol['is_outlier_iqr']]\n",
    "\n",
    "print(f\"\\nOutlier dates:\")\n",
    "for idx, row in outlier_days.iterrows():\n",
    "    print(f\"  {row['date'].strftime('%Y-%m-%d')}: {row['total_enrolments']:,.0f} enrolments\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(daily_enrol['date'], daily_enrol['total_enrolments'], \n",
    "        color='#3A86FF', linewidth=2, label='Daily Enrolments')\n",
    "\n",
    "# Highlight outliers\n",
    "if len(outlier_days) > 0:\n",
    "    ax.scatter(outlier_days['date'], outlier_days['total_enrolments'],\n",
    "              color='#E63946', s=100, marker='o', label='Outliers (IQR)', zorder=3)\n",
    "\n",
    "# Add threshold lines\n",
    "ax.axhline(y=iqr_outliers['upper_bound'], color='#FB5607', \n",
    "          linestyle='--', linewidth=2, label='Upper Bound')\n",
    "ax.axhline(y=iqr_outliers['lower_bound'], color='#FB5607', \n",
    "          linestyle='--', linewidth=2, label='Lower Bound')\n",
    "\n",
    "ax.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Total Enrolments', fontweight='bold', fontsize=12)\n",
    "ax.set_title('IQR Outlier Detection: Daily Enrolment Volume', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/23_iqr_outliers.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af56f4",
   "metadata": {},
   "source": [
    "### 2.2 Z-Score Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score detection\n",
    "zscore_outliers = detector.detect_outliers_zscore(\n",
    "    daily_enrol['total_enrolments'].values,\n",
    "    threshold=3.0\n",
    ")\n",
    "\n",
    "print(f\"=== Z-SCORE OUTLIER DETECTION ===\\n\")\n",
    "print(f\"Threshold: ¬±3 standard deviations\")\n",
    "print(f\"Outliers detected: {zscore_outliers['n_outliers']}\")\n",
    "print(f\"Outlier percentage: {zscore_outliers['outlier_percentage']:.2f}%\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Mean: {zscore_outliers['mean']:,.0f}\")\n",
    "print(f\"  Std Dev: {zscore_outliers['std']:,.0f}\")\n",
    "\n",
    "daily_enrol['is_outlier_zscore'] = zscore_outliers['is_outlier']\n",
    "outlier_days_z = daily_enrol[daily_enrol['is_outlier_zscore']]\n",
    "\n",
    "print(f\"\\nOutlier dates (Z-score > 3):\")\n",
    "for idx, row in outlier_days_z.iterrows():\n",
    "    z = (row['total_enrolments'] - zscore_outliers['mean']) / zscore_outliers['std']\n",
    "    print(f\"  {row['date'].strftime('%Y-%m-%d')}: {row['total_enrolments']:,.0f} (Z={z:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b286d4a",
   "metadata": {},
   "source": [
    "### 2.3 Modified Z-Score (Robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03594869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Z-score (uses median instead of mean)\n",
    "mod_zscore_outliers = detector.detect_outliers_modified_zscore(\n",
    "    daily_enrol['total_enrolments'].values,\n",
    "    threshold=3.5\n",
    ")\n",
    "\n",
    "print(f\"=== MODIFIED Z-SCORE OUTLIER DETECTION ===\\n\")\n",
    "print(f\"Threshold: ¬±3.5 (robust method using median)\")\n",
    "print(f\"Outliers detected: {mod_zscore_outliers['n_outliers']}\")\n",
    "print(f\"Outlier percentage: {mod_zscore_outliers['outlier_percentage']:.2f}%\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Median: {mod_zscore_outliers['median']:,.0f}\")\n",
    "print(f\"  MAD: {mod_zscore_outliers['mad']:,.0f}\")\n",
    "\n",
    "daily_enrol['is_outlier_mod_z'] = mod_zscore_outliers['is_outlier']\n",
    "\n",
    "# Compare all three methods\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['IQR', 'Z-Score', 'Modified Z-Score'],\n",
    "    'Outliers': [iqr_outliers['n_outliers'], \n",
    "                zscore_outliers['n_outliers'], \n",
    "                mod_zscore_outliers['n_outliers']],\n",
    "    'Percentage': [iqr_outliers['outlier_percentage'], \n",
    "                   zscore_outliers['outlier_percentage'], \n",
    "                   mod_zscore_outliers['outlier_percentage']]\n",
    "})\n",
    "\n",
    "print(\"\\n=== METHOD COMPARISON ===\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = comparison['Method']\n",
    "counts = comparison['Outliers']\n",
    "colors = ['#3A86FF', '#FB5607', '#8338EC']\n",
    "\n",
    "bars = ax.bar(methods, counts, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(count)}',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=14)\n",
    "\n",
    "ax.set_ylabel('Number of Outliers', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Outlier Detection Method Comparison', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/24_outlier_method_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79af90",
   "metadata": {},
   "source": [
    "## 3. TEMPORAL ANOMALY DETECTION\n",
    "\n",
    "### 3.1 Weekly Aggregation Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series\n",
    "ts_data = daily_enrol.set_index('date')['total_enrolments']\n",
    "\n",
    "# Detect temporal anomalies\n",
    "temporal_anomalies = detector.detect_temporal_anomalies(\n",
    "    ts_data,\n",
    "    window=7,\n",
    "    threshold=2.0\n",
    ")\n",
    "\n",
    "print(f\"=== TEMPORAL ANOMALY DETECTION ===\\n\")\n",
    "print(f\"Window size: 7 days (weekly)\")\n",
    "print(f\"Threshold: 2.0 standard deviations\")\n",
    "print(f\"Anomalies detected: {temporal_anomalies['n_anomalies']}\")\n",
    "print(f\"Anomaly percentage: {temporal_anomalies['anomaly_percentage']:.2f}%\")\n",
    "\n",
    "# Show anomaly dates\n",
    "anomaly_dates = ts_data[temporal_anomalies['is_anomaly']]\n",
    "print(f\"\\nTemporal anomalies:\")\n",
    "for date, value in anomaly_dates.items():\n",
    "    print(f\"  {date.strftime('%Y-%m-%d')}: {value:,.0f} enrolments\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(ts_data.index, ts_data.values, \n",
    "        color='#3A86FF', linewidth=2, label='Daily Enrolments')\n",
    "\n",
    "# Plot rolling mean and std bands\n",
    "rolling_mean = temporal_anomalies['rolling_mean']\n",
    "rolling_std = temporal_anomalies['rolling_std']\n",
    "\n",
    "ax.plot(ts_data.index, rolling_mean, \n",
    "        color='#FB5607', linewidth=2, linestyle='--', label='7-Day Moving Average')\n",
    "\n",
    "# Upper/lower bounds\n",
    "upper_bound = rolling_mean + (2.0 * rolling_std)\n",
    "lower_bound = rolling_mean - (2.0 * rolling_std)\n",
    "ax.fill_between(ts_data.index, lower_bound, upper_bound, \n",
    "                alpha=0.2, color='#FB5607', label='¬±2 Std Dev Band')\n",
    "\n",
    "# Mark anomalies\n",
    "if len(anomaly_dates) > 0:\n",
    "    ax.scatter(anomaly_dates.index, anomaly_dates.values,\n",
    "              color='#E63946', s=100, marker='X', label='Temporal Anomalies', zorder=3)\n",
    "\n",
    "ax.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Total Enrolments', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Temporal Anomaly Detection: 7-Day Rolling Window', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/25_temporal_anomalies.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8242298",
   "metadata": {},
   "source": [
    "### 3.2 Changepoint Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6840bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect changepoints\n",
    "changepoints = detector.detect_changepoints(\n",
    "    ts_data.values,\n",
    "    penalty=10\n",
    ")\n",
    "\n",
    "print(f\"=== CHANGEPOINT DETECTION ===\\n\")\n",
    "print(f\"Penalty parameter: 10\")\n",
    "print(f\"Changepoints detected: {changepoints['n_changepoints']}\")\n",
    "\n",
    "if changepoints['n_changepoints'] > 0:\n",
    "    print(f\"\\nChangepoint indices:\")\n",
    "    for cp_idx in changepoints['changepoint_indices']:\n",
    "        cp_date = ts_data.index[cp_idx]\n",
    "        cp_value = ts_data.iloc[cp_idx]\n",
    "        print(f\"  Index {cp_idx}: {cp_date.strftime('%Y-%m-%d')} (value: {cp_value:,.0f})\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(ts_data.index, ts_data.values, \n",
    "        color='#3A86FF', linewidth=2, label='Daily Enrolments')\n",
    "\n",
    "# Mark changepoints\n",
    "if changepoints['n_changepoints'] > 0:\n",
    "    for cp_idx in changepoints['changepoint_indices']:\n",
    "        ax.axvline(x=ts_data.index[cp_idx], color='#E63946', \n",
    "                  linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Total Enrolments', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Changepoint Detection: Structural Breaks in Time Series', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add custom legend entry for changepoints\n",
    "if changepoints['n_changepoints'] > 0:\n",
    "    from matplotlib.lines import Line2D\n",
    "    custom_lines = [Line2D([0], [0], color='#3A86FF', linewidth=2),\n",
    "                   Line2D([0], [0], color='#E63946', linewidth=2, linestyle='--')]\n",
    "    ax.legend(custom_lines, ['Daily Enrolments', 'Changepoints'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/26_changepoint_detection.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec35621",
   "metadata": {},
   "source": [
    "## 4. MACHINE LEARNING-BASED ANOMALY DETECTION\n",
    "\n",
    "### 4.1 Isolation Forest - Daily Enrolments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for ML detection\n",
    "features_df = daily_enrol[['total_enrolments']].copy()\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest_results = detector.detect_isolation_forest(\n",
    "    features_df.values,\n",
    "    contamination=0.05,  # Expect 5% anomalies\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"=== ISOLATION FOREST ANOMALY DETECTION ===\\n\")\n",
    "print(f\"Contamination parameter: 0.05 (5%)\")\n",
    "print(f\"Anomalies detected: {iso_forest_results['n_anomalies']}\")\n",
    "print(f\"Anomaly percentage: {iso_forest_results['anomaly_percentage']:.2f}%\")\n",
    "\n",
    "daily_enrol['is_anomaly_ml'] = iso_forest_results['is_anomaly']\n",
    "daily_enrol['anomaly_score'] = iso_forest_results['anomaly_scores']\n",
    "\n",
    "ml_anomalies = daily_enrol[daily_enrol['is_anomaly_ml']]\n",
    "\n",
    "print(f\"\\nML-detected anomalies (sorted by score):\")\n",
    "ml_sorted = ml_anomalies.sort_values('anomaly_score')\n",
    "for idx, row in ml_sorted.head(10).iterrows():\n",
    "    print(f\"  {row['date'].strftime('%Y-%m-%d')}: {row['total_enrolments']:,.0f} \"\n",
    "          f\"(score: {row['anomaly_score']:.3f})\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Time series with anomalies\n",
    "ax1.plot(daily_enrol['date'], daily_enrol['total_enrolments'], \n",
    "        color='#3A86FF', linewidth=2, label='Daily Enrolments')\n",
    "\n",
    "if len(ml_anomalies) > 0:\n",
    "    ax1.scatter(ml_anomalies['date'], ml_anomalies['total_enrolments'],\n",
    "               color='#E63946', s=100, marker='D', label='ML Anomalies', zorder=3)\n",
    "\n",
    "ax1.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Total Enrolments', fontweight='bold', fontsize=12)\n",
    "ax1.set_title('Isolation Forest Anomaly Detection', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Anomaly scores\n",
    "colors = ['#E63946' if is_anom else '#3A86FF' \n",
    "         for is_anom in daily_enrol['is_anomaly_ml']]\n",
    "ax2.scatter(daily_enrol['date'], daily_enrol['anomaly_score'], \n",
    "           c=colors, alpha=0.6, s=30)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "ax2.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('Anomaly Score', fontweight='bold', fontsize=12)\n",
    "ax2.set_title('Isolation Forest Anomaly Scores (Negative = Anomaly)', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/27_isolation_forest_anomalies.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a026193",
   "metadata": {},
   "source": [
    "### 4.2 Multi-Feature Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multi-dimensional features\n",
    "state_daily = enrolment_df.groupby(['date', 'state'])['total_enrolments'].sum().reset_index()\n",
    "state_pivot = state_daily.pivot(index='date', columns='state', values='total_enrolments').fillna(0)\n",
    "\n",
    "# Use top 10 states as features\n",
    "top_10_states = enrolment_df.groupby('state')['total_enrolments'].sum().nlargest(10).index\n",
    "feature_matrix = state_pivot[top_10_states].values\n",
    "\n",
    "print(f\"=== MULTI-FEATURE ANOMALY DETECTION ===\\n\")\n",
    "print(f\"Feature dimensions: {feature_matrix.shape}\")\n",
    "print(f\"Features: Top 10 states' daily enrolments\")\n",
    "\n",
    "# Apply Isolation Forest\n",
    "multi_iso_results = detector.detect_isolation_forest(\n",
    "    feature_matrix,\n",
    "    contamination=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nAnomalies detected: {multi_iso_results['n_anomalies']}\")\n",
    "print(f\"Anomaly percentage: {multi_iso_results['anomaly_percentage']:.2f}%\")\n",
    "\n",
    "# Add results to dataframe\n",
    "multi_df = pd.DataFrame({\n",
    "    'date': state_pivot.index,\n",
    "    'is_anomaly': multi_iso_results['is_anomaly'],\n",
    "    'anomaly_score': multi_iso_results['anomaly_scores']\n",
    "})\n",
    "\n",
    "multi_anomalies = multi_df[multi_df['is_anomaly']]\n",
    "\n",
    "print(f\"\\nMulti-feature anomaly dates:\")\n",
    "for idx, row in multi_anomalies.iterrows():\n",
    "    print(f\"  {row['date'].strftime('%Y-%m-%d')}: score = {row['anomaly_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9936f6",
   "metadata": {},
   "source": [
    "## 5. GEOGRAPHIC ANOMALY PATTERNS\n",
    "\n",
    "### 5.1 State-Level Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate state totals\n",
    "state_totals = enrolment_df.groupby('state')['total_enrolments'].sum()\n",
    "\n",
    "# Detect state-level outliers\n",
    "state_outliers = detector.detect_outliers_iqr(state_totals.values, threshold=1.5)\n",
    "\n",
    "print(f\"=== GEOGRAPHIC ANOMALIES (State Level) ===\\n\")\n",
    "print(f\"Total states: {len(state_totals)}\")\n",
    "print(f\"Anomalous states: {state_outliers['n_outliers']}\")\n",
    "print(f\"Outlier percentage: {state_outliers['outlier_percentage']:.2f}%\")\n",
    "\n",
    "state_df = pd.DataFrame({\n",
    "    'state': state_totals.index,\n",
    "    'total_enrolments': state_totals.values,\n",
    "    'is_outlier': state_outliers['is_outlier']\n",
    "})\n",
    "\n",
    "outlier_states = state_df[state_df['is_outlier']].sort_values('total_enrolments', ascending=False)\n",
    "\n",
    "print(f\"\\nOutlier states (exceptionally high or low):\")\n",
    "for idx, row in outlier_states.iterrows():\n",
    "    print(f\"  {row['state']:30s}: {row['total_enrolments']:10,.0f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "colors = ['#E63946' if outlier else '#3A86FF' for outlier in state_df['is_outlier']]\n",
    "sorted_states = state_df.sort_values('total_enrolments', ascending=True)\n",
    "\n",
    "bars = ax.barh(range(len(sorted_states)), sorted_states['total_enrolments'], \n",
    "              color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(sorted_states)))\n",
    "ax.set_yticklabels(sorted_states['state'], fontsize=8)\n",
    "ax.set_xlabel('Total Enrolments', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('State', fontweight='bold', fontsize=12)\n",
    "ax.set_title('State-Level Anomalies: Enrolment Distribution', \n",
    "             fontweight='bold', fontsize=14, pad=20)\n",
    "ax.grid(True, axis='x', alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#3A86FF', label='Normal'),\n",
    "                   Patch(facecolor='#E63946', label='Outlier')]\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/28_geographic_anomalies.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738acc91",
   "metadata": {},
   "source": [
    "### 5.2 District-Level Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District totals\n",
    "district_totals = enrolment_df.groupby('district')['total_enrolments'].sum()\n",
    "\n",
    "# Detect district-level outliers\n",
    "district_outliers = detector.detect_outliers_iqr(district_totals.values, threshold=1.5)\n",
    "\n",
    "print(f\"=== GEOGRAPHIC ANOMALIES (District Level) ===\\n\")\n",
    "print(f\"Total districts: {len(district_totals)}\")\n",
    "print(f\"Anomalous districts: {district_outliers['n_outliers']}\")\n",
    "print(f\"Outlier percentage: {district_outliers['outlier_percentage']:.2f}%\")\n",
    "\n",
    "district_df = pd.DataFrame({\n",
    "    'district': district_totals.index,\n",
    "    'total_enrolments': district_totals.values,\n",
    "    'is_outlier': district_outliers['is_outlier']\n",
    "})\n",
    "\n",
    "outlier_districts = district_df[district_df['is_outlier']].sort_values(\n",
    "    'total_enrolments', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 outlier districts:\")\n",
    "for idx, row in outlier_districts.head(20).iterrows():\n",
    "    print(f\"  {row['district']:30s}: {row['total_enrolments']:10,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eba285",
   "metadata": {},
   "source": [
    "## 6. ANOMALY SUMMARY & INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ANOMALY DETECTION - KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä STATISTICAL OUTLIERS (Daily Enrolments):\")\n",
    "print(f\"  ‚Ä¢ IQR method: {iqr_outliers['n_outliers']} outliers ({iqr_outliers['outlier_percentage']:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ Z-score method: {zscore_outliers['n_outliers']} outliers ({zscore_outliers['outlier_percentage']:.2f}%)\")\n",
    "print(f\"  ‚Ä¢ Modified Z-score: {mod_zscore_outliers['n_outliers']} outliers ({mod_zscore_outliers['outlier_percentage']:.2f}%)\")\n",
    "\n",
    "print(\"\\nüïí TEMPORAL ANOMALIES:\")\n",
    "print(f\"  ‚Ä¢ Rolling window anomalies: {temporal_anomalies['n_anomalies']}\")\n",
    "print(f\"  ‚Ä¢ Changepoints detected: {changepoints['n_changepoints']}\")\n",
    "\n",
    "print(\"\\nü§ñ MACHINE LEARNING DETECTION:\")\n",
    "print(f\"  ‚Ä¢ Isolation Forest (univariate): {iso_forest_results['n_anomalies']} anomalies\")\n",
    "print(f\"  ‚Ä¢ Isolation Forest (multi-feature): {multi_iso_results['n_anomalies']} anomalies\")\n",
    "\n",
    "print(\"\\nüó∫Ô∏è  GEOGRAPHIC ANOMALIES:\")\n",
    "print(f\"  ‚Ä¢ State-level outliers: {state_outliers['n_outliers']} states\")\n",
    "print(f\"  ‚Ä¢ District-level outliers: {district_outliers['n_outliers']} districts\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(\"  ‚Ä¢ Statistical methods provide baseline outlier detection\")\n",
    "print(\"  ‚Ä¢ ML-based methods capture complex, multi-dimensional patterns\")\n",
    "print(\"  ‚Ä¢ Temporal anomalies reveal unusual activity periods\")\n",
    "print(\"  ‚Ä¢ Geographic outliers highlight states/districts with exceptional volumes\")\n",
    "print(\"  ‚Ä¢ Changepoints indicate structural shifts in enrolment patterns\")\n",
    "\n",
    "print(\"\\n‚úì Anomaly detection completed successfully\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
